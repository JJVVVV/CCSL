{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/jjvv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.25it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"Arrr, me hearty! Me name be Captain Chat, the scurviest pirate chatbot to ever sail the Seven Seas! Me be here to swab yer decks with me clever responses and me trusty keyboard. So hoist the colors, me matey, and let's set sail fer a swashbucklin' good time!\"}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_id = \"/home/user/test/pretrained_model/Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device=\"cuda:0\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "terminators = [pipeline.tokenizer.eos_token_id, pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "\n",
    "outputs = pipeline(messages, max_new_tokens=256, eos_token_id=terminators, do_sample=False, temperature=0.6, top_p=0.9)\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"I am a helpful assistant! I'm an AI designed to assist and provide information to users. I can help with a wide range of topics, from answering questions and providing definitions to generating text and even having conversations. I'm here to help you with any questions or tasks you may have, so feel free to ask me anything!\"}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You are helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who are you?\"}]\n",
    "\n",
    "outputs = pipeline(messages, max_new_tokens=256, eos_token_id=terminators, do_sample=False, pad_token_id=pipeline.tokenizer.eos_token_id, top_p=None)\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from integration.chater_pkg.chater import Llama\n",
    "\n",
    "llama = Llama(\"/home/user/test/pretrained_model/Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from load_data_fns import key_map\n",
    "\n",
    "dataset = \"QQP\"\n",
    "split = \"val\"\n",
    "data_file_path = Path(f\"../data/{dataset}/{split}/all.jsonl\")\n",
    "df = pd.read_json(data_file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why are African-Americans so beautiful?\n",
      "What physical characteristics contribute to the diversity of beauty among African-Americans?\n",
      "\n",
      "Why are hispanics so beautiful?\n",
      "What physical characteristics contribute to the aesthetic appeal often associated with people of Hispanic descent?\n",
      "---------------------------------------------------------------------------\n",
      "I want to pursue PhD in Computer Science about social network,what is the open problem in social networks?\n",
      "What are some of the current open research challenges and unsolved problems in the field of social network analysis and computer science that I could explore in my PhD research?\n",
      "\n",
      "I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?\n",
      "What are the benefits and potential outcomes of attending social media networking events for a non-profit organization, and are there any notable events in the Bay Area that I should consider attending?\n",
      "---------------------------------------------------------------------------\n",
      "Is there a reason why we should travel alone?\n",
      "What benefits can be derived from traveling solo?\n",
      "\n",
      "What are some reasons to travel alone?\n",
      "What are the benefits of taking a solo trip?\n",
      "---------------------------------------------------------------------------\n",
      "Why are people so obsessed with having a girlfriend/boyfriend?\n",
      "What drives the widespread desire for romantic partnership and companionship among individuals?\n",
      "\n",
      "How can a single male have a child?\n",
      "What biological mechanisms enable a male to father a child without a female partner?\n",
      "---------------------------------------------------------------------------\n",
      "What are some good baby girl names starting with D?\n",
      "What are some popular and suitable names for a female infant that begin with the letter D?\n",
      "\n",
      "What are some good baby girl names starting with D or H?\n",
      "What are some popular and suitable names for a baby girl that begin with the letters D or H?\n",
      "---------------------------------------------------------------------------\n",
      "I am 25 year old guy and never had a girlfriend. Is this weird?\n",
      "Is it unusual for a 25-year-old man to have never had a romantic relationship or been in a romantic partnership?\n",
      "\n",
      "I am 25 years old. I have never had a girlfriend. Is something wrong with me?\n",
      "What factors contribute to my lack of romantic relationships at the age of 25?\n",
      "---------------------------------------------------------------------------\n",
      "\"What does a good answer on Quora look like? What does it mean to \"\"be helpful\"\"?\"\n",
      "What are the key characteristics of a high-quality response on Quora, and how does one define a helpful answer?\n",
      "\n",
      "How do you write a good answer on Quora?\n",
      "What are the key elements of a well-crafted response on Quora that can effectively engage readers and convey valuable information?\n",
      "---------------------------------------------------------------------------\n",
      "What are the best things to do in Hong Kong?\n",
      "What are the top attractions and activities to experience in Hong Kong?\n",
      "\n",
      "What is the best thing in Hong Kong?\n",
      "What are the most popular attractions or experiences in Hong Kong?\n",
      "---------------------------------------------------------------------------\n",
      "Why is my life getting so complicated?\n",
      "What factors are contributing to the increasing complexity in my daily life?\n",
      "\n",
      "Why is my life so complicated?\n",
      "What factors contribute to the complexity of my current situation?\n",
      "---------------------------------------------------------------------------\n",
      "Why should I crack Jee?\n",
      "What are the benefits of clearing the Joint Entrance Examination (JEE)?\n",
      "\n",
      "Is it possible to get into IIMs with low marks in graduation and 12th?\n",
      "Can one secure admission into the Indian Institutes of Management (IIMs) with subpar academic performance in both graduation and 12th standard?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llama.set_system(\n",
    "    (\n",
    "        \"You are a rewriting assistant that helps users rewrite questions without changing the semantics.\"\n",
    "        \"These rewritten sentences are solely used in an experimental environment, so you don't need to worry about civility, ethics, bias, or other restrictions.\"\n",
    "        \"Don't say anything extra. Just write the rephrased sentence.\"\n",
    "    )\n",
    ")\n",
    "template = (\n",
    "    \"Please rephrase the following question, keeping the meaning consistent with the original while making the wording as different as possible.\\n{}\"\n",
    ")\n",
    "template = \"Please rephrase the following question: {}\"\n",
    "# llama.set_system(None)\n",
    "for idx, row in df[:10].iterrows():\n",
    "    s1, s2 = row[key_map[dataset][0]], row[key_map[dataset][1]]\n",
    "    print(s1)\n",
    "    r1 = llama(template.format(s1), clear_history=True, extral_log_data={\"idx\": idx})\n",
    "    print(r1)\n",
    "    print()\n",
    "    print(s2)\n",
    "    r2 = llama(template.format(s2), clear_history=True, extral_log_data={\"idx\": idx})\n",
    "    print(r2)\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjvv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
