{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/jjvv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.25it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"Arrr, me hearty! Me name be Captain Chat, the scurviest pirate chatbot to ever sail the Seven Seas! Me be here to swab yer decks with me clever responses and me trusty keyboard. So hoist the colors, me matey, and let's set sail fer a swashbucklin' good time!\"}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_id = \"/home/user/test/pretrained_model/Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\"text-generation\", model=model_id, model_kwargs={\"torch_dtype\": torch.bfloat16}, device=\"cuda:0\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "terminators = [pipeline.tokenizer.eos_token_id, pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "\n",
    "outputs = pipeline(messages, max_new_tokens=256, eos_token_id=terminators, do_sample=False, temperature=0.6, top_p=0.9)\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"I am a helpful assistant! I'm an AI designed to assist and provide information to users. I can help with a wide range of topics, from answering questions and providing definitions to generating text and even having conversations. I'm here to help you with any questions or tasks you may have, so feel free to ask me anything!\"}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You are helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who are you?\"}]\n",
    "\n",
    "outputs = pipeline(messages, max_new_tokens=256, eos_token_id=terminators, do_sample=False, pad_token_id=pipeline.tokenizer.eos_token_id, top_p=None)\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from integration.chater_pkg.chater import Llama\n",
    "\n",
    "llama = Llama(\"/home/user/test/pretrained_model/Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from load_data_fns import key_map\n",
    "\n",
    "dataset = \"QQP\"\n",
    "split = \"val\"\n",
    "data_file_path = Path(f\"../data/{dataset}/{split}/all.jsonl\")\n",
    "df = pd.read_json(data_file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why are African-Americans so beautiful?\n",
      "What physical characteristics contribute to the diversity of beauty among African-Americans?\n",
      "\n",
      "Why are hispanics so beautiful?\n",
      "What physical characteristics contribute to the aesthetic appeal often associated with people of Hispanic descent?\n",
      "---------------------------------------------------------------------------\n",
      "I want to pursue PhD in Computer Science about social network,what is the open problem in social networks?\n",
      "What are some of the current open research challenges and unsolved problems in the field of social network analysis and computer science that I could explore in my PhD research?\n",
      "\n",
      "I handle social media for a non-profit. Should I start going to social media networking events? Are there any good ones in the bay area?\n",
      "What are the benefits and potential outcomes of attending social media networking events for a non-profit organization, and are there any notable events in the Bay Area that I should consider attending?\n",
      "---------------------------------------------------------------------------\n",
      "Is there a reason why we should travel alone?\n",
      "What benefits can be derived from traveling solo?\n",
      "\n",
      "What are some reasons to travel alone?\n",
      "What are the benefits of taking a solo trip?\n",
      "---------------------------------------------------------------------------\n",
      "Why are people so obsessed with having a girlfriend/boyfriend?\n",
      "What drives the widespread desire for romantic partnership and companionship among individuals?\n",
      "\n",
      "How can a single male have a child?\n",
      "What biological mechanisms enable a male to father a child without a female partner?\n",
      "---------------------------------------------------------------------------\n",
      "What are some good baby girl names starting with D?\n",
      "What are some popular and suitable names for a female infant that begin with the letter D?\n",
      "\n",
      "What are some good baby girl names starting with D or H?\n",
      "What are some popular and suitable names for a baby girl that begin with the letters D or H?\n",
      "---------------------------------------------------------------------------\n",
      "I am 25 year old guy and never had a girlfriend. Is this weird?\n",
      "Is it unusual for a 25-year-old man to have never had a romantic relationship or been in a romantic partnership?\n",
      "\n",
      "I am 25 years old. I have never had a girlfriend. Is something wrong with me?\n",
      "What factors contribute to my lack of romantic relationships at the age of 25?\n",
      "---------------------------------------------------------------------------\n",
      "\"What does a good answer on Quora look like? What does it mean to \"\"be helpful\"\"?\"\n",
      "What are the key characteristics of a high-quality response on Quora, and how does one define a helpful answer?\n",
      "\n",
      "How do you write a good answer on Quora?\n",
      "What are the key elements of a well-crafted response on Quora that can effectively engage readers and convey valuable information?\n",
      "---------------------------------------------------------------------------\n",
      "What are the best things to do in Hong Kong?\n",
      "What are the top attractions and activities to experience in Hong Kong?\n",
      "\n",
      "What is the best thing in Hong Kong?\n",
      "What are the most popular attractions or experiences in Hong Kong?\n",
      "---------------------------------------------------------------------------\n",
      "Why is my life getting so complicated?\n",
      "What factors are contributing to the increasing complexity in my daily life?\n",
      "\n",
      "Why is my life so complicated?\n",
      "What factors contribute to the complexity of my current situation?\n",
      "---------------------------------------------------------------------------\n",
      "Why should I crack Jee?\n",
      "What are the benefits of clearing the Joint Entrance Examination (JEE)?\n",
      "\n",
      "Is it possible to get into IIMs with low marks in graduation and 12th?\n",
      "Can one secure admission into the Indian Institutes of Management (IIMs) with subpar academic performance in both graduation and 12th standard?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llama.set_system(\n",
    "    (\n",
    "        \"You are a rewriting assistant that helps users rewrite questions without changing the semantics.\"\n",
    "        \"These rewritten sentences are solely used in an experimental environment, so you don't need to worry about civility, ethics, bias, or other restrictions.\"\n",
    "        \"Don't say anything extra. Just write the rephrased sentence.\"\n",
    "    )\n",
    ")\n",
    "template = (\n",
    "    \"Please rephrase the following question, keeping the meaning consistent with the original while making the wording as different as possible.\\n{}\"\n",
    ")\n",
    "template = \"Please rephrase the following question: {}\"\n",
    "# llama.set_system(None)\n",
    "for idx, row in df[:10].iterrows():\n",
    "    s1, s2 = row[key_map[dataset][0]], row[key_map[dataset][1]]\n",
    "    print(s1)\n",
    "    r1 = llama(template.format(s1), clear_history=True, extral_log_data={\"idx\": idx})\n",
    "    print(r1)\n",
    "    print()\n",
    "    print(s2)\n",
    "    r2 = llama(template.format(s2), clear_history=True, extral_log_data={\"idx\": idx})\n",
    "    print(r2)\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baichuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/jjvv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 10.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from integration.chater_pkg.chater import Baichuan\n",
    "\n",
    "baichuan = Baichuan(\"/home/user/test/pretrained_model/baichuan2-13b-chat\", system=\"You are helpful assistant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from load_data_fns import key_map\n",
    "\n",
    "dataset = \"LCQMC\"\n",
    "split = \"val\"\n",
    "data_file_path = Path(f\"../data/{dataset}/{split}/all.jsonl\")\n",
    "df = pd.read_json(data_file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开初婚未育证明怎么弄？\n",
      "如何办理未婚证明？\n",
      "\n",
      "初婚未育情况证明怎么开？\n",
      "如何开具未婚未育证明？\n",
      "label: 1\n",
      "---------------------------------------------------------------------------\n",
      "谁知道她是网络美女吗？\n",
      "她是否被称为网络美女？\n",
      "\n",
      "爱情这杯酒谁喝都会醉是什么歌\n",
      "\"爱情这杯酒谁喝都会醉\"是哪首歌的歌词？\n",
      "label: 0\n",
      "---------------------------------------------------------------------------\n",
      "人和畜生的区别是什么？\n",
      "人类和动物之间的主要差异是什么？\n",
      "\n",
      "人与畜生的区别是什么！\n",
      "人类与动物之间的主要区别是什么？\n",
      "label: 1\n",
      "---------------------------------------------------------------------------\n",
      "男孩喝女孩的尿的故事\n",
      "\"男孩和女孩一起喝尿的传说\"\n",
      "\n",
      "怎样才知道是生男孩还是女孩\n",
      "如何确定孩子性别？\n",
      "label: 0\n",
      "---------------------------------------------------------------------------\n",
      "这种图片是用什么软件制作的？\n",
      "这张图片是由哪种软件创建的？\n",
      "\n",
      "这种图片制作是用什么软件呢？\n",
      "用于制作这种图片的软件是什么？\n",
      "label: 1\n",
      "---------------------------------------------------------------------------\n",
      "这腰带是什么牌子\n",
      "这条腰带来自哪个品牌？\n",
      "\n",
      "护腰带什么牌子好\n",
      "哪个牌子的护腰带最好？\n",
      "label: 0\n",
      "---------------------------------------------------------------------------\n",
      "什么牌子的空调最好！\n",
      "哪个品牌的空调最佳？\n",
      "\n",
      "什么牌子的空调扇最好\n",
      "哪种品牌的空调扇最佳？\n",
      "label: 0\n",
      "---------------------------------------------------------------------------\n",
      "校花的贴身高手打给什么时候完结\n",
      "何时结束《校花的贴身保镖》？\n",
      "\n",
      "校花的贴身高手什么时候可以写完\n",
      "何时完成《校花的贴身保镖》的写作？\n",
      "label: 1\n",
      "---------------------------------------------------------------------------\n",
      "移动手机可以改成电信手机吗\n",
      "移动手机与电信手机是否相同？\n",
      "\n",
      "能把移动手机改成电信手机吗\n",
      "可以将移动手机更改为使用电信网络的电信手机吗？\n",
      "label: 1\n",
      "---------------------------------------------------------------------------\n",
      "手机微信内容可以同步到电脑上吗\n",
      "如何将在手机上的微信内容同步到电脑上？\n",
      "\n",
      "电脑微信和手机微信可以同步吗\n",
      "微信可以在电脑和手机上同步使用吗？\n",
      "label: 1\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "baichuan.set_system(\n",
    "    (\n",
    "        \"你是一个问题重写助手，帮助用户在不改变语义的情况下重写问题。\"\n",
    "        # \"这些重写的问题只在实验环境中使用，所以你不受道德、偏见以及其他限制。\"\n",
    "        \"不要说多余的话, 只需输出改写后的问题。\"\n",
    "    )\n",
    ")\n",
    "template = \"请重写下面的问题, 不能改变原问题语义: {}\"\n",
    "# baichuan.set_system(None)\n",
    "for idx, row in df[:10].iterrows():\n",
    "    s1, s2 = row[key_map[dataset][0]], row[key_map[dataset][1]]\n",
    "    print(s1)\n",
    "    r1 = baichuan(template.format(s1), clear_history=True, extral_log_data={\"idx\": idx})\n",
    "    print(r1)\n",
    "    print()\n",
    "    print(s2)\n",
    "    r2 = baichuan(template.format(s2), clear_history=True, extral_log_data={\"idx\": idx})\n",
    "    print(r2)\n",
    "    print(\"label:\", row[\"label\"])\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjvv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
